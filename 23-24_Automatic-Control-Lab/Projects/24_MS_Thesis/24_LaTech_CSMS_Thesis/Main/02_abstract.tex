\chapter*{ABSTRACT}
\addcontentsline{toc}{chapter}{ABSTRACT}

{Robotic Odor Source Localization (ROSL) technology allows autonomous agents like robots to find an odor source in unknown environments. A successful odor source location depends crucially on an effective navigation algorithm that directs the robot towards the odor source. This thesis is a combination of three projects. First, we detail development of a versatile multi-modal robotic platform for ROSL real-world ROSL experimentation and discussed real-world validation of a traditional olfaction-based ROSL algorithm. Secondly, we introduced vision in ROSL by proposing a fusion navigation algorithm that integrates deep-learning enabled vision and olfaction-based navigation. This hybrid approach tackles challenges such as turbulent airflow, which can disrupt olfaction sensing, and physical obstacles within the search area, which may hinder vision detection. Thirdly, we introduce multi-modal reasoning-based navigation algorithm. This approach utilizes zero-shot reasoning capabilities of multi-modal Large Language Model (LLM) in novel situations. To evaluate the effectiveness of the three implemented algorithms, we conducted real-world ROSL navigation experiments. Experimental results demonstrated that 1) the developed real-world robot platform can be utilized to validate ROSL algorithms, 2) the proposed incorporation of vision sensing  outperforms olfaction-only methods, and 3) zero-shot LLM reasoning-based method is effective in ROSL.}